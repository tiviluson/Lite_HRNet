# Deploy Lite_HRNet with ONNX format

## Overview

Check section **Tasks** for more details

## How to run the files
1. Install dependencies with `pip install -r requirements.txt`.
2. Use `Demo.ipynb` for an interactive demo.
3. Use `main.py` for the FastAPI server, `test.py` to test the server.

## Tasks

- [x] Run inference with model Lite_HRNet with MMPose's API
- [x] Rewrite the model to convert it to ONNX format
- [x] Run inference with model Lite_HRNet in ONNX format
- [x] Visualize output
- [x] Build FastAPI server to demostrate the project
- [ ] Build Dockerfile for the project
- [ ] Run and test Dockerfile for the project
- [ ] Deploy the model on Cloud (along with K8S?)
